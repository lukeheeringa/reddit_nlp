{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "honey-magazine",
   "metadata": {},
   "source": [
    "#### Step 3: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medieval-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/cleaned_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['title']\n",
    "y = data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "familiar-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-satin",
   "metadata": {},
   "source": [
    "Before starting to evaluate any classification models, it's important to determine a baseline of accuracy for comparing results. This null model will use the most commonly occuring target value in the training data as a prediction for every value in the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-oregon",
   "metadata": {},
   "source": [
    "#### Step 3A: Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adolescent-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coffee    0.50275\n",
       "tea       0.49725\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "declared-accounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coffee    0.502604\n",
       "tea       0.497396\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-speech",
   "metadata": {},
   "source": [
    "Guessing 'Coffee' for every sample gives us a null accuracy of 50.3%, only slightly off from the 50% we would have expected had all samples been kept and the classes were exactly even."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-gospel",
   "metadata": {},
   "source": [
    "#### Step 3B: Natural Language Processing & Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-respondent",
   "metadata": {},
   "source": [
    "The first step in our modeling process will be to transform our text. This will include any preprocessing in the form of tokenization, stemming, or lemmatization, the actual transformer that we'll use to vectorize the tokens, and the hyperparameters that we'll feed into that transformer, like n-gram size, the minimum and maximum number of samples a token must occur in to be included, and the number of tokens we ultimately want to see used as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-presence",
   "metadata": {},
   "source": [
    "There are two main vectorizers we've been using to consider:\n",
    "- CountVectorizer, which gives a simple count of tokens as matrix values\n",
    "- TfidfVectorizer (TFDIF: 'term frequency'-'inverse document frequency'), which creates a matrix which assigns value based on how often a term occurs in the target class vs how often it occurs in the sample as a whole\n",
    "\n",
    "Both vectorizers will require a tokenizer to be specified to break up the text into words or phrases as well as process things like punctuation. This could be a simple tokenizer that just grabs the words as they appear in the sample text, or a tokenizer that includes lemmatization, the process of attempting to reduce a word to a base form in order to count all the forms a word might take as the same feature (i.e. ideally 'run,' 'ran,' and 'running' would all become 'run'). \n",
    "\n",
    "For this model, I will be testing the default basic tokenizer as well as a custom tokenizer that incorporates the WordNetLemmatizer. \n",
    "\n",
    "Further work could be done to specify custom regular expressions ('regex') for tokenization or a more powerful NLP library like spaCy could be used, but prior testing has shown that neither one will provide a significant improvement to this model to justify their complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aquatic-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this custom wordnetlemmatizer code has been taken from:\n",
    "# https://stackoverflow.com/questions/47423854/sklearn-adding-lemmatizer-to-countvectorizer\n",
    "# and is similar to code found in lesson 5.04 NLP II\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-comment",
   "metadata": {},
   "source": [
    "To test what kind of vectorizer to use, I'll use GridSearchCV to test out different combinations of vectorizers, tokenizers, and hyperparameters. For comparison, they will all use a naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "choice-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "vector_params = {\n",
    "    'vect' : [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vect__tokenizer' : [None, LemmaTokenizer()],\n",
    "    'vect__stop_words' : [None, 'english'],\n",
    "    'vect__ngram_range' : [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__min_df' : [1, 2, 5],\n",
    "    'vect__max_features' : [None, 1000, 2500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_grid = GridSearchCV(vector_pipe, param_grid=vector_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-trunk",
   "metadata": {},
   "source": [
    "Instead of rerunning the timely search several times, I saved the results of the cell below before commenting out the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "phantom-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_grid.fit(X_train, y_train)\n",
    "# vector_search = pd.DataFrame(vector_grid.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "# vector_search.to_csv('../grid_search/vectorizers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-channel",
   "metadata": {},
   "source": [
    "I can then load the saved results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nonprofit-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = pd.read_csv('../grid_search/vectorizers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "saving-suffering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>param_vect__stop_words</th>\n",
       "      <th>param_vect__tokenizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.307686</td>\n",
       "      <td>0.030241</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2), stop_words...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>&lt;__main__.LemmaTokenizer object at 0x1a13778310&gt;</td>\n",
       "      <td>{'vect': CountVectorizer(ngram_range=(1, 2), s...</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.914616</td>\n",
       "      <td>0.914616</td>\n",
       "      <td>0.931983</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.919537</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261823</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.285279</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2), stop_words...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>&lt;__main__.LemmaTokenizer object at 0x1a13778310&gt;</td>\n",
       "      <td>{'vect': CountVectorizer(ngram_range=(1, 2), s...</td>\n",
       "      <td>0.911722</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.913169</td>\n",
       "      <td>0.937771</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143002</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.023360</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2), stop_words...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'vect': CountVectorizer(ngram_range=(1, 2), s...</td>\n",
       "      <td>0.914616</td>\n",
       "      <td>0.908828</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.930535</td>\n",
       "      <td>0.924747</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112515</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2), stop_words...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'vect': CountVectorizer(ngram_range=(1, 2), s...</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.931983</td>\n",
       "      <td>0.923300</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.203209</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.289473</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2), stop_words...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>&lt;__main__.LemmaTokenizer object at 0x1a13778310&gt;</td>\n",
       "      <td>{'vect': CountVectorizer(ngram_range=(1, 2), s...</td>\n",
       "      <td>0.923300</td>\n",
       "      <td>0.904486</td>\n",
       "      <td>0.911722</td>\n",
       "      <td>0.930535</td>\n",
       "      <td>0.913169</td>\n",
       "      <td>0.916643</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.307686      0.030241         0.290893        0.007107   \n",
       "1       1.261823      0.028666         0.285279        0.009024   \n",
       "2       0.143002      0.007003         0.023360        0.001405   \n",
       "3       0.112515      0.007200         0.022423        0.002819   \n",
       "4       1.203209      0.120937         0.289473        0.025417   \n",
       "\n",
       "                                          param_vect  \\\n",
       "0  CountVectorizer(ngram_range=(1, 2), stop_words...   \n",
       "1  CountVectorizer(ngram_range=(1, 2), stop_words...   \n",
       "2  CountVectorizer(ngram_range=(1, 2), stop_words...   \n",
       "3  CountVectorizer(ngram_range=(1, 2), stop_words...   \n",
       "4  CountVectorizer(ngram_range=(1, 2), stop_words...   \n",
       "\n",
       "   param_vect__max_features  param_vect__min_df param_vect__ngram_range  \\\n",
       "0                       NaN                   1                  (1, 2)   \n",
       "1                       NaN                   2                  (1, 2)   \n",
       "2                    2500.0                   2                  (1, 2)   \n",
       "3                       NaN                   2                  (1, 2)   \n",
       "4                       NaN                   1                  (1, 1)   \n",
       "\n",
       "  param_vect__stop_words                             param_vect__tokenizer  \\\n",
       "0                english  <__main__.LemmaTokenizer object at 0x1a13778310>   \n",
       "1                english  <__main__.LemmaTokenizer object at 0x1a13778310>   \n",
       "2                english                                               NaN   \n",
       "3                english                                               NaN   \n",
       "4                english  <__main__.LemmaTokenizer object at 0x1a13778310>   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'vect': CountVectorizer(ngram_range=(1, 2), s...           0.917511   \n",
       "1  {'vect': CountVectorizer(ngram_range=(1, 2), s...           0.911722   \n",
       "2  {'vect': CountVectorizer(ngram_range=(1, 2), s...           0.914616   \n",
       "3  {'vect': CountVectorizer(ngram_range=(1, 2), s...           0.916064   \n",
       "4  {'vect': CountVectorizer(ngram_range=(1, 2), s...           0.923300   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.914616           0.914616           0.931983           0.918958   \n",
       "1           0.910275           0.913169           0.937771           0.916064   \n",
       "2           0.908828           0.905933           0.930535           0.924747   \n",
       "3           0.910275           0.903039           0.931983           0.923300   \n",
       "4           0.904486           0.911722           0.930535           0.913169   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.919537        0.006446                1  \n",
       "1         0.917800        0.010167                2  \n",
       "2         0.916932        0.009361                3  \n",
       "3         0.916932        0.010051                3  \n",
       "4         0.916643        0.009180                5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-essex",
   "metadata": {},
   "source": [
    "The results show that the top performing models used the CountVectorizer with minimum occurences of 1 or 2, monograms and bigrams, stop words removed, lemmatization with the custom LemmaTokenizer, and no maximum features.\n",
    "\n",
    "I'll use the second best performing vectorization model moving forward, as limiting the features to occurring in a minimum of 2 samples will significantly reduce the number of features being used in calculations without significantly impacting accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unusual-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(ngram_range=(1, 2), stop_words='english', min_df=2, tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-black",
   "metadata": {},
   "source": [
    "#### Step 3C: Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-compiler",
   "metadata": {},
   "source": [
    "For the classification itself, I'll be testing several different models as well as fine tuning their respective hyperparameters. I'll begin with three singular models: a naive Bayes classifier, logistic regression, and a support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extended-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_pipe = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "bayes_params = {\n",
    "    'bayes__alpha' : [0.001, 1, 100, 100_000, 1_000_000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wired-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_grid = GridSearchCV(bayes_pipe, bayes_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-percentage",
   "metadata": {},
   "source": [
    "Like with the vectorizers above, I'll be saving and loading the results of the grid searches to keep from running the searches more than necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "going-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes_grid.fit(X_train, y_train)\n",
    "# bayes_search = pd.DataFrame(bayes_grid.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "# bayes_search.to_csv('../grid_search/naivebayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "organizational-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search = pd.read_csv('../grid_search/naivebayes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "electoral-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bayes__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.986317</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.442080</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>100000.000</td>\n",
       "      <td>{'bayes__alpha': 100000}</td>\n",
       "      <td>0.901592</td>\n",
       "      <td>0.892909</td>\n",
       "      <td>0.879884</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.888567</td>\n",
       "      <td>0.894645</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.104413</td>\n",
       "      <td>0.142098</td>\n",
       "      <td>0.454980</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>100.000</td>\n",
       "      <td>{'bayes__alpha': 100}</td>\n",
       "      <td>0.863965</td>\n",
       "      <td>0.868307</td>\n",
       "      <td>0.855282</td>\n",
       "      <td>0.888567</td>\n",
       "      <td>0.869754</td>\n",
       "      <td>0.869175</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.438170</td>\n",
       "      <td>0.131440</td>\n",
       "      <td>0.553253</td>\n",
       "      <td>0.095937</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{'bayes__alpha': 1}</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.875543</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.857019</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.190884</td>\n",
       "      <td>2.276147</td>\n",
       "      <td>0.580462</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'bayes__alpha': 0.001}</td>\n",
       "      <td>0.849493</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>0.843705</td>\n",
       "      <td>0.872648</td>\n",
       "      <td>0.853835</td>\n",
       "      <td>0.851520</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.818018</td>\n",
       "      <td>0.359644</td>\n",
       "      <td>0.626132</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>1000000.000</td>\n",
       "      <td>{'bayes__alpha': 1000000}</td>\n",
       "      <td>0.659913</td>\n",
       "      <td>0.651230</td>\n",
       "      <td>0.633864</td>\n",
       "      <td>0.625181</td>\n",
       "      <td>0.617945</td>\n",
       "      <td>0.637627</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.986317      0.016954         0.442080        0.019782   \n",
       "1       2.104413      0.142098         0.454980        0.030158   \n",
       "2       2.438170      0.131440         0.553253        0.095937   \n",
       "3       7.190884      2.276147         0.580462        0.012110   \n",
       "4       1.818018      0.359644         0.626132        0.211996   \n",
       "\n",
       "   param_bayes__alpha                     params  split0_test_score  \\\n",
       "0          100000.000   {'bayes__alpha': 100000}           0.901592   \n",
       "1             100.000      {'bayes__alpha': 100}           0.863965   \n",
       "2               1.000        {'bayes__alpha': 1}           0.859624   \n",
       "3               0.001    {'bayes__alpha': 0.001}           0.849493   \n",
       "4         1000000.000  {'bayes__alpha': 1000000}           0.659913   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.892909           0.879884           0.910275           0.888567   \n",
       "1           0.868307           0.855282           0.888567           0.869754   \n",
       "2           0.845152           0.845152           0.875543           0.859624   \n",
       "3           0.837916           0.843705           0.872648           0.853835   \n",
       "4           0.651230           0.633864           0.625181           0.617945   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.894645        0.010492                1  \n",
       "1         0.869175        0.010930                2  \n",
       "2         0.857019        0.011299                3  \n",
       "3         0.851520        0.011849                4  \n",
       "4         0.637627        0.015736                5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-living",
   "metadata": {},
   "source": [
    "Here we can again see that the large alpha parameter of 100,000 is the best performing on the dataset, with a mean score of .895. We can also check how it performs on the full training set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rolled-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('bayes', MultinomialNB(alpha=100000))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_pipe = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('bayes', MultinomialNB(alpha=100_000))\n",
    "])\n",
    "\n",
    "bayes_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interim-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502170767004342"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "smoking-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8880208333333334"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-success",
   "metadata": {},
   "source": [
    "There's a fair gap between the train and test scores, indicating that the model is overfitting, but this tends to be the norm for a naive Bayes classifier and isn't surprising for data that could see such large differences like vocabulary choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-muscle",
   "metadata": {},
   "source": [
    "I'll search over logistic regression next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "upset-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression(solver='saga'))\n",
    "])\n",
    "\n",
    "lr_params= {\n",
    "    'lr__penalty' : ['l1', 'l2'],\n",
    "    'lr__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'lr__max_iter' : [100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "therapeutic-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(lr_pipe, param_grid=lr_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "earned-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_grid.fit(X_train, y_train)\n",
    "# lr_search = pd.DataFrame(lr_grid.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "# lr_search.to_csv('../grid_search/logisticregression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "separate-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_search = pd.read_csv('../grid_search/logisticregression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "necessary-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>param_lr__max_iter</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.745059</td>\n",
       "      <td>0.123086</td>\n",
       "      <td>0.384371</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>0.100</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'lr__C': 0.1, 'lr__max_iter': 100, 'lr__penal...</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.920405</td>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.915195</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.333631</td>\n",
       "      <td>1.740514</td>\n",
       "      <td>0.470107</td>\n",
       "      <td>0.176817</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'lr__C': 0.1, 'lr__max_iter': 1000, 'lr__pena...</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.908828</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.907670</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.666374</td>\n",
       "      <td>0.568221</td>\n",
       "      <td>0.366477</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>1.000</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'lr__C': 1, 'lr__max_iter': 100, 'lr__penalty...</td>\n",
       "      <td>0.908828</td>\n",
       "      <td>0.890014</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.913169</td>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.904197</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.028229</td>\n",
       "      <td>0.040023</td>\n",
       "      <td>0.434689</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'lr__C': 0.001, 'lr__max_iter': 1000, 'lr__pe...</td>\n",
       "      <td>0.904486</td>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>0.903618</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.886967</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'lr__C': 0.001, 'lr__max_iter': 100, 'lr__pen...</td>\n",
       "      <td>0.904486</td>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>0.903618</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_lr__C  \\\n",
       "0       4.745059      0.123086         0.384371        0.049956        0.100   \n",
       "1      15.333631      1.740514         0.470107        0.176817        0.100   \n",
       "2      11.666374      0.568221         0.366477        0.029431        1.000   \n",
       "3       2.028229      0.040023         0.434689        0.016125        0.001   \n",
       "4       1.886967      0.025981         0.410863        0.011716        0.001   \n",
       "\n",
       "   param_lr__max_iter param_lr__penalty  \\\n",
       "0                 100                l1   \n",
       "1                1000                l1   \n",
       "2                 100                l1   \n",
       "3                1000                l2   \n",
       "4                 100                l2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'lr__C': 0.1, 'lr__max_iter': 100, 'lr__penal...           0.918958   \n",
       "1  {'lr__C': 0.1, 'lr__max_iter': 1000, 'lr__pena...           0.910275   \n",
       "2  {'lr__C': 1, 'lr__max_iter': 100, 'lr__penalty...           0.908828   \n",
       "3  {'lr__C': 0.001, 'lr__max_iter': 1000, 'lr__pe...           0.904486   \n",
       "4  {'lr__C': 0.001, 'lr__max_iter': 100, 'lr__pen...           0.904486   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.920405           0.907381           0.918958           0.910275   \n",
       "1           0.908828           0.905933           0.903039           0.910275   \n",
       "2           0.890014           0.910275           0.913169           0.898698   \n",
       "3           0.898698           0.903039           0.917511           0.894356   \n",
       "4           0.898698           0.903039           0.917511           0.894356   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.915195        0.005305                1  \n",
       "1         0.907670        0.002806                2  \n",
       "2         0.904197        0.008606                3  \n",
       "3         0.903618        0.007799                4  \n",
       "4         0.903618        0.007799                4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-clear",
   "metadata": {},
   "source": [
    "Here we see our highest performance with an l1 penalty, a C value of 0.1, and a maximum of 100 iterations.\n",
    "\n",
    "The highest mean test score was .915, and we can check performance on the full training set and the test set next: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "outside-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('lr', LogisticRegression(C=0.1, penalty='l1', solver='saga'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe1 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression(penalty='l1', C=.1, max_iter=100, solver='saga'))\n",
    "])\n",
    "\n",
    "lr_pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "forbidden-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777134587554269"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "becoming-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-operations",
   "metadata": {},
   "source": [
    "We can see that the logistic regression outperforms the naive Bayes on the train data and the test data, but also shows signs of overfit.\n",
    "\n",
    "With that in mind, we can check the scores with some smaller C values, corresponding with stronger regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hollow-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.05, penalty='l1', solver='saga'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe2 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression(solver='saga', penalty='l1', max_iter=100, C=0.05))\n",
    "])\n",
    "\n",
    "lr_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pressed-letter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623733719247467"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "saving-skiing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210069444444444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-laptop",
   "metadata": {},
   "source": [
    "Through some trial and error, it seems like that without majorly sacrificing train and test accuracy in the name of curbing overfit, the best parameters are an l1 penalty with a C value of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-expense",
   "metadata": {},
   "source": [
    "The next model I'll try is the support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "addressed-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipe = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "svc_params= {\n",
    "    'svc__kernel' : ['rbf', 'sigmoid', 'poly'],\n",
    "    'svc__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cognitive-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = GridSearchCV(svc_pipe, param_grid=svc_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "composite-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_grid.fit(X_train, y_train)\n",
    "# svc_search = pd.DataFrame(svc_grid.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "# svc_search.to_csv('../grid_search/svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "english-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_search = pd.read_csv('../grid_search/svc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "welsh-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.830177</td>\n",
       "      <td>0.115086</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.135840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'sigmoid'}</td>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.879884</td>\n",
       "      <td>0.890014</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.904486</td>\n",
       "      <td>0.896961</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.082071</td>\n",
       "      <td>0.137042</td>\n",
       "      <td>0.645653</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'svc__C': 10, 'svc__kernel': 'rbf'}</td>\n",
       "      <td>0.897250</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.875543</td>\n",
       "      <td>0.872648</td>\n",
       "      <td>0.888567</td>\n",
       "      <td>0.878726</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.189655</td>\n",
       "      <td>0.139689</td>\n",
       "      <td>0.641812</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'rbf'}</td>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.852388</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>0.876990</td>\n",
       "      <td>0.874096</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.984897</td>\n",
       "      <td>0.064087</td>\n",
       "      <td>0.665470</td>\n",
       "      <td>0.058165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'svc__C': 100, 'svc__kernel': 'rbf'}</td>\n",
       "      <td>0.881331</td>\n",
       "      <td>0.846599</td>\n",
       "      <td>0.850941</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.882779</td>\n",
       "      <td>0.864544</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.836434</td>\n",
       "      <td>0.164419</td>\n",
       "      <td>0.501529</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 10, 'svc__kernel': 'sigmoid'}</td>\n",
       "      <td>0.859624</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.862518</td>\n",
       "      <td>0.862518</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>0.860203</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_svc__C  \\\n",
       "0       2.830177      0.115086         0.699153        0.135840           1.0   \n",
       "1       3.082071      0.137042         0.645653        0.027951          10.0   \n",
       "2       3.189655      0.139689         0.641812        0.036743           1.0   \n",
       "3       2.984897      0.064087         0.665470        0.058165         100.0   \n",
       "4       2.836434      0.164419         0.501529        0.042660          10.0   \n",
       "\n",
       "  param_svc__kernel                                    params  \\\n",
       "0           sigmoid   {'svc__C': 1, 'svc__kernel': 'sigmoid'}   \n",
       "1               rbf      {'svc__C': 10, 'svc__kernel': 'rbf'}   \n",
       "2               rbf       {'svc__C': 1, 'svc__kernel': 'rbf'}   \n",
       "3               rbf     {'svc__C': 100, 'svc__kernel': 'rbf'}   \n",
       "4           sigmoid  {'svc__C': 10, 'svc__kernel': 'sigmoid'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.907381           0.879884           0.890014           0.903039   \n",
       "1           0.897250           0.859624           0.875543           0.872648   \n",
       "2           0.898698           0.852388           0.871201           0.871201   \n",
       "3           0.881331           0.846599           0.850941           0.861071   \n",
       "4           0.859624           0.845152           0.862518           0.862518   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.904486         0.896961        0.010412                1  \n",
       "1           0.888567         0.878726        0.013054                2  \n",
       "2           0.876990         0.874096        0.014843                3  \n",
       "3           0.882779         0.864544        0.015056                4  \n",
       "4           0.871201         0.860203        0.008468                5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cellular-entrance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('svc', SVC(kernel='sigmoid'))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe1 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', SVC(kernel='sigmoid'))\n",
    "])\n",
    "\n",
    "svc_pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "moral-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577424023154848"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "explicit-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8923611111111112"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-catering",
   "metadata": {},
   "source": [
    "The best model appears to be the sigmoid kernel with a C value of 1. Trial of different C values was not able to significantly reduce the gap between the train and test scores or improve the test accuracy. We can also compare the gap to the gaussian kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "earned-ethernet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('svc', SVC(C=1))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe2 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', SVC(C=1))\n",
    "])\n",
    "\n",
    "svc_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "composite-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748191027496382"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "provincial-secretariat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715277777777778"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-brake",
   "metadata": {},
   "source": [
    "Across different C values, the gaussian kernel performed worse on the test data than the sigmoid kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-share",
   "metadata": {},
   "source": [
    "Next I'll look at an ensembling model, the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "distant-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipe = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('rfc', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "rfc_params= {\n",
    "    'rfc__criterion' : ['gini', 'entropy'],\n",
    "    'rfc__n_estimators' : [10, 100, 1000],\n",
    "    'rfc__max_depth' : [3, 5, 10, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dependent-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid = GridSearchCV(rfc_pipe, param_grid=rfc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "plain-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_grid.fit(X_train, y_train)\n",
    "# rfc_search = pd.DataFrame(rfc_grid.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "# rfc_search.to_csv('./grid_search/randomforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "automated-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search = pd.read_csv('../grid_search/randomforest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "moderate-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__criterion</th>\n",
       "      <th>param_rfc__max_depth</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.297346</td>\n",
       "      <td>0.075845</td>\n",
       "      <td>0.321364</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__max_depth': N...</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.913867</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.102440</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.318379</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__max_depth'...</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.917333</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.397004</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.114382</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__max_depth': N...</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.373960</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.114435</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__max_depth'...</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.913067</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__max_depth': N...</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.906400</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.297346      0.075845         0.321364        0.003114   \n",
       "1       3.102440      0.037014         0.318379        0.003102   \n",
       "2       0.397004      0.015792         0.114382        0.001129   \n",
       "3       0.373960      0.013042         0.114435        0.002338   \n",
       "4       0.088379      0.010437         0.113634        0.001857   \n",
       "\n",
       "  param_rfc__criterion  param_rfc__max_depth  param_rfc__n_estimators  \\\n",
       "0                 gini                   NaN                     1000   \n",
       "1              entropy                   NaN                     1000   \n",
       "2                 gini                   NaN                      100   \n",
       "3              entropy                   NaN                      100   \n",
       "4                 gini                   NaN                       10   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'rfc__criterion': 'gini', 'rfc__max_depth': N...           0.916000   \n",
       "1  {'rfc__criterion': 'entropy', 'rfc__max_depth'...           0.913333   \n",
       "2  {'rfc__criterion': 'gini', 'rfc__max_depth': N...           0.914667   \n",
       "3  {'rfc__criterion': 'entropy', 'rfc__max_depth'...           0.913333   \n",
       "4  {'rfc__criterion': 'gini', 'rfc__max_depth': N...           0.918667   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.926667           0.906667           0.914667           0.905333   \n",
       "1           0.932000           0.901333           0.917333           0.904000   \n",
       "2           0.922667           0.902667           0.920000           0.908000   \n",
       "3           0.930667           0.902667           0.914667           0.904000   \n",
       "4           0.920000           0.896000           0.905333           0.892000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.913867        0.007664                1  \n",
       "1         0.913600        0.010911                2  \n",
       "2         0.913600        0.007419                3  \n",
       "3         0.913067        0.010028                4  \n",
       "4         0.906400        0.011420                5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-grave",
   "metadata": {},
   "source": [
    "The best parameters were found to be gini criterion, 1000 estimators, and no limit on depth. We can see the performance on train and test sets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "partial-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('rfc', RandomForestClassifier(n_estimators=1000, n_jobs=-1))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe1 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('rfc', RandomForestClassifier(criterion='gini', n_estimators=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rfc_pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "protective-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939218523878437"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "actual-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940972222222222"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-satellite",
   "metadata": {},
   "source": [
    "The training score is very high, indicating there's definitely overfit happening. We can test to see if other parameters avoided overfit any better or were able to increase the accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "incorporated-surfing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(criterion='entropy', n_estimators=1000,\n",
       "                                        n_jobs=-1))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe2 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('rfc', RandomForestClassifier(criterion='entropy', n_estimators=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rfc_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "elder-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939218523878437"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "minute-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8949652777777778"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-vegetarian",
   "metadata": {},
   "source": [
    "Entropy as a criterion seems to score slightly better on the test set than gini.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "declared-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('rfc', RandomForestClassifier(n_jobs=-1))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe3 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('rfc', RandomForestClassifier(criterion='gini', n_estimators=100, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rfc_pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "turkish-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939218523878437"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "antique-canada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8862847222222222"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-retirement",
   "metadata": {},
   "source": [
    "Seems like the higher number of estimators didn't actually add much to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bizarre-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvect',\n",
       "                 CountVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x10300ea90>)),\n",
       "                ('sscaler', StandardScaler(with_mean=False)),\n",
       "                ('rfc', RandomForestClassifier(max_depth=75, n_jobs=-1))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe4 = Pipeline([\n",
    "    ('cvect', cvect),\n",
    "    ('sscaler', StandardScaler(with_mean=False)),\n",
    "    ('rfc', RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=75, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rfc_pipe4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "early-facility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583212735166425"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "potential-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010416666666666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-flesh",
   "metadata": {},
   "source": [
    "No matter the parameters, the gap between the train score and the test score remains between about 4 and 8 points, but a max depth of 75 gives us the highest test set score of 90.9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
